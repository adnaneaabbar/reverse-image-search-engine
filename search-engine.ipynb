{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import hamming, cosine\n",
    "\n",
    "%matplotlib inline\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset utils and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(path, size):\n",
    "    # String path to image\n",
    "    # Tuple size of output image\n",
    "    image = cv.imread(path)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BAYER_BGR2RGB)\n",
    "    image = cv.resize(image, size, cv.INTER_CUBIC)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preprocessing(dataset_path, labels_file_path, size, image_paths_pickle):\n",
    "    # String path to dataset\n",
    "    # String path to labels file\n",
    "    # Tuple size of image\n",
    "    # String name of pickle file where image paths are stored\n",
    "    with open(labels_file_path, 'r') as f:\n",
    "        classes = f.read().split('\\n')[:-1]\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for image_name in os.listdir(dataset_path):\n",
    "        try:\n",
    "            image_path = os.path.join(dataset_path, image_name)\n",
    "            images.append(image_loader(image_path, size))\n",
    "            image_paths.append(image_path)\n",
    "            for idx in range(len(classes)):\n",
    "                if classes[idx] in image_name:\n",
    "                    labels.append(idx)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    with open(image_paths_pickle + \".pickle\", 'wb') as f:\n",
    "        pickle.dump(image_paths, f)\n",
    "    \n",
    "    assert len(images) == len(labels)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(training_set_vectors, query_vector, top_n=30):\n",
    "    \n",
    "    distances = []\n",
    "    # comparing each image to all training set\n",
    "    for i in range(len(training_set_vectors)):\n",
    "        distances.append(cosine(training_set_vectors[i], query_vector[0]))\n",
    "    # return sorted indices of 30 most similar images\n",
    "    return np.argsort(distances)[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(training_set_vectors, query_vector, top_n=50):\n",
    "\n",
    "    distances = []\n",
    "    # comparing each image to all training set\n",
    "    for i in range(len(training_set_vectors)):\n",
    "        distances.append(hamming(training_set_vectors[i], query_vector[0]))\n",
    "    # return sorted indices of 30 most similar images   \n",
    "    return np.argsort(distances)[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sparse accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_accuracy(true_labels, predicted_labels):\n",
    "\n",
    "    # np array real labels of each sample\n",
    "    # np matrix softmax probabilities\n",
    "    \n",
    "    assert len(true_labels) == len(predicted_labels)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if np.argmax(predicted_labels[i]) == true_labels[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(size):\n",
    "    # tuple of (height, width) of an image\n",
    "    # shape = [batch_size, size[0], size[1], 3]  we set batch_size to None so it accepts any number\n",
    "    # defining CNN inputs as placeholders\n",
    "    inputs = tf.placeholder(dtype=tf.float32, shape=[None, size[0], size[1], 3], name='images')\n",
    "    targets = tf.placeholder(dtype=tf.int32, shape=[None,], name='targets') # array of true labels\n",
    "    dropout_prob = tf.placeholder(dtype=tf.float32, name='dropout_probs')\n",
    "    \n",
    "    return inputs, targets, dropout_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs,                  # data from a previous layer\n",
    "               number_of_filters,       # integer, number of conv filters\n",
    "               kernel_size,             # tuple, size of conv layer kernel\n",
    "               strides=(1, 1),          \n",
    "               padding='SAME',          # string, type of padding technique: SAME or VALID\n",
    "               activation=tf.nn.relu,   # tf.object, activation function used on the layer\n",
    "               max_pool=True,           # boolean, if true the conv block will use max_pool\n",
    "               batch_norm=True):        # boolean, if true the conv block will use batch normalization\n",
    "    \n",
    "    conv_features = layer = tf.layers.conv2d(inputs=inputs, \n",
    "                                             filters=number_of_filters, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             strides=strides, \n",
    "                                             padding=padding, \n",
    "                                             activation=activation)\n",
    "    \n",
    "    if max_pool:\n",
    "        layer = tf.layers.max_pooling2d(layer, \n",
    "                                        pool_size=(2, 2), \n",
    "                                        strides=(2, 2),\n",
    "                                        padding='SAME')\n",
    "        \n",
    "    if batch_norm:\n",
    "        layer = tf.layers.batch_normalization(layer)\n",
    "        \n",
    "    return layer, conv_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(inputs,                 # data from a previous layer\n",
    "                units,                  # integer, number of neurons/units for a dense layer\n",
    "                activation=tf.nn.relu,  # tf.object, activation function used on the layer\n",
    "                dropout_rate=None,      # dropout rate used in this dense block\n",
    "                batch_norm=True):       # boolean, if true the conv block will use batch normalization\n",
    "    \n",
    "    dense_features = layer = tf.layers.dense(inputs, \n",
    "                                             units=units, \n",
    "                                             activation=activation)\n",
    "    \n",
    "    if dropout_rate is not None:\n",
    "        layer = tf.layers.dropout(layer, rate=dropout_rate)\n",
    "    \n",
    "    if batch_norm:\n",
    "        layer = tf.layers.batch_normalization(layer)\n",
    "        \n",
    "    return layer, dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_loss(logits,            # pre-activated model outputs\n",
    "             targets,           # true labels for each input sample\n",
    "             learning_rate):\n",
    "    # sparse means that we don't have to convert our targets to one hot encoding version\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    # Adam optimizer performs best on CNNs\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    return loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to README.md to see the complete summary of the model when following along this cell of code\n",
    "class ImageSearchModel(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 learning_rate, \n",
    "                 size,                  # tuple of (height, width) of an image\n",
    "                 number_of_classes=10): # integer number of classes in a dataset\n",
    "        \n",
    "        tf.reset_default_graph() # escape possibility of having nested models graphs\n",
    "        \n",
    "        # model inputs\n",
    "        self.inputs, self.targets, self.dropout_rate = model_inputs(size)\n",
    "        # every image is 0 to 255, so we add batch norm layer\n",
    "        normalized_images = tf.layers.batch_normalization(self.inputs)\n",
    "        \n",
    "        # conv_1 block\n",
    "        conv_block_1, self.conv_1_features = conv_block(inputs=normalized_images, \n",
    "                                                        number_of_filters=64, \n",
    "                                                        kernel_size=(3, 3), \n",
    "                                                        strides=(1, 1), \n",
    "                                                        padding='SAME', \n",
    "                                                        activation=tf.nn.relu, \n",
    "                                                        max_pool=True, \n",
    "                                                        batch_norm=True)\n",
    "        # conv_2 block\n",
    "        conv_block_2, self.conv_2_features = conv_block(inputs=conv_block_1, \n",
    "                                                        number_of_filters=128, \n",
    "                                                        kernel_size=(3, 3), \n",
    "                                                        strides=(1, 1), \n",
    "                                                        padding='SAME', \n",
    "                                                        activation=tf.nn.relu, \n",
    "                                                        max_pool=True, \n",
    "                                                        batch_norm=True)\n",
    "        # conv_3 block\n",
    "        conv_block_3, self.conv_3_features = conv_block(inputs=conv_block_2, \n",
    "                                                        number_of_filters=256, \n",
    "                                                        kernel_size=(5, 5), \n",
    "                                                        strides=(1, 1), \n",
    "                                                        padding='SAME', \n",
    "                                                        activation=tf.nn.relu, \n",
    "                                                        max_pool=True, \n",
    "                                                        batch_norm=True)\n",
    "        # conv_4 block\n",
    "        conv_block_4, self.conv_4_features = conv_block(inputs=conv_block_3, \n",
    "                                                        number_of_filters=512, \n",
    "                                                        kernel_size=(5, 5), \n",
    "                                                        strides=(1, 1), \n",
    "                                                        padding='SAME', \n",
    "                                                        activation=tf.nn.relu, \n",
    "                                                        max_pool=True, \n",
    "                                                        batch_norm=True)\n",
    "        # flattening the last conv lock to one single vector flat_layer\n",
    "        flat_layer = tf.layers.flatten(conv_block_4)\n",
    "\n",
    "        # dense_1 block\n",
    "        dense_block_1, dense_1_features = dense_block(inputs=flat_layer, \n",
    "                                                       units=128, \n",
    "                                                       activation=tf.nn.relu, \n",
    "                                                       dropout_rate=self.dropout_rate, \n",
    "                                                       batch_norm=True)\n",
    "        # dense_2 block\n",
    "        dense_block_2, self.dense_2_features = dense_block(inputs=dense_block_1, \n",
    "                                                       units=256, \n",
    "                                                       activation=tf.nn.relu, \n",
    "                                                       dropout_rate=self.dropout_rate, \n",
    "                                                       batch_norm=True) \n",
    "        # dense_3 block\n",
    "        dense_block_3, self.dense_3_features = dense_block(inputs=dense_block_2, \n",
    "                                                       units=512, \n",
    "                                                       activation=tf.nn.relu, \n",
    "                                                       dropout_rate=self.dropout_rate, \n",
    "                                                       batch_norm=True)\n",
    "        # dense_4 block\n",
    "        dense_block_4, self.dense_4_features = dense_block(inputs=dense_block_3, \n",
    "                                                       units=1024, \n",
    "                                                       activation=tf.nn.relu, \n",
    "                                                       dropout_rate=self.dropout_rate, \n",
    "                                                       batch_norm=True)  \n",
    "        # output layer\n",
    "        logits = tf.layers.dense(inputs=dense_block_4, \n",
    "                                 units=number_of_classes, \n",
    "                                 activation=None)\n",
    "        \n",
    "        self.predictions = tf.nn.softmax(logits)  # turn logits into a probs vector perdictions\n",
    "        \n",
    "        self.loss, self.optimizer = opt_loss(logits=logits, \n",
    "                                             targets=self.targets, \n",
    "                                             learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit2d2a7b7d88554f6bbdade15fa4e28b95",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}